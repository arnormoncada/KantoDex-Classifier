# ğŸš€ KantoDex-Classifier Project

## ğŸŒŸ Overview

Welcome to the **KantoDex-Classifier** project! This repository is designed to identify Generation I PokÃ©mon using deep neural networks. 

## ğŸ“ Project Structure

```
KantoDex-Classifier/
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .ruff.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ download_dataset.py
â”œâ”€â”€ environment.yml
â”œâ”€â”€ setup_env.sh
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ augmentation/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ augmentor.py
    â”œâ”€â”€ config/
    â”‚   â””â”€â”€ config.yaml
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ data_loader.py
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ custom_model.py
    â”‚   â””â”€â”€ model.py
    â””â”€â”€ utils/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ helpers.py
```

## ğŸ› ï¸ Included Components

### 1. **Source Code (`src/`):**
   - **Models (`src/models/`):**
     - `model.py`: Defines the `KantoDexClassifier`, a custom neural network tailored for PokÃ©mon classification.
     - `custom_model.py`: Implements advanced architectural components like positional encoding, SE blocks, and multi-head self-attention.
   - **Data Loading (`src/data/`):**
     - `data_loader.py`: Contains the `PokemonDataset` class and functions to load and preprocess the dataset.
   - **Augmentation (`src/augmentation/`):**
     - `augmentor.py`: Implements data augmentation techniques to enhance model robustness.
   - **Utilities (`src/utils/`):**
     - `helpers.py`: Provides helper functions for checkpointing and directory management.
   - **Configuration (`src/config/`):**
     - `config.yaml`: YAML configuration file outlining parameters for data processing, training, augmentation, and model settings.

### 2. **Scripts:**
   - `setup_env.sh`: Shell script to set up the Conda environment based on `environment.yml`.
   - `download_dataset.py`: Script to download and organize the PokÃ©mon dataset from Kaggle.
   - `train.py`: Training script for the model, integrated with TensorBoard for real-time monitoring.

### 3. **Configuration Files:**
   - `.env.example`: Example environment variables file for Kaggle API credentials.
   - `environment.yml`: Conda environment specification listing all dependencies.
   - `.ruff.toml`: Configuration for Ruff, the linter, ensuring code quality and consistency.
   - `.gitignore`: Specifies files and directories to be ignored by Git to maintain repository cleanliness.


## ğŸ“‹ Setup Instructions

### 1. **Clone the Repository**
```bash
git clone https://github.com/arnormoncada/KantoDex-Classifier.git
cd KantoDex-Classifier
```

### 2. **Set Up the Environment**
```bash
./setup_env.sh
```

### 3. **Configure Kaggle API**
- Rename `.env.example` to `.env` and populate it with your Kaggle API credentials.
  
  **Example:**
  ```bash
  cp .env.example .env
  nano .env
  ```
  
  **.env:**
  ```
  # Kaggle API credentials
  KAGGLE_USERNAME=your_kaggle_username
  KAGGLE_KEY=your_kaggle_key
  ```

### 4. **Download the Dataset**
Ensure you have set up Kaggle API credentials. Execute the script to download and organize the dataset.

```bash
python download_dataset.py
```

### 5. **Train the Model**
```bash
python train.py
```

#### 5.1 **Resume Training**
If you wish to continue training from the latest checkpoint:

```bash
python train.py --resume
```

## ğŸ“Š Using TensorBoard

TensorBoard is integrated into the training pipeline to monitor metrics like loss and accuracy in real-time.

1. **Launch TensorBoard**
   ```bash
   tensorboard --logdir=runs
   ```
2. **Access TensorBoard**
   - Open your browser and navigate to [http://localhost:6006/](http://localhost:6006/) to view the dashboard.

## ğŸ“ Additional Notes

- **Environment Consistency:** Ensure that you are using Python 3.11 as specified in the `environment.yml`.
- **Dependency Management:** All dependencies are managed via Conda. If you encounter issues, verify that the environment is correctly set up.
- **Code Quality:** The project adheres to PEP 8 standards, enforced by Ruff. Ensure that all new code passes linting checks.
- **Data Security:** The `.env` file containing Kaggle API credentials is excluded from version control to maintain security.